<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Voice Chat Live API Test</title>
    <style>
        body { font-family: Arial, sans-serif; background: #f8f9fa; }
        .container { max-width: 600px; margin: 40px auto; background: #fff; border-radius: 8px; box-shadow: 0 2px 8px #0001; padding: 32px; }
        h1 { color: #0051BA; }
        #status { margin: 16px 0; font-weight: bold; }
        #log { background: #eee; padding: 12px; border-radius: 6px; height: 180px; overflow-y: auto; font-size: 13px; }
        #micBtn { background: #0051BA; color: #fff; border: none; border-radius: 50%; width: 64px; height: 64px; font-size: 32px; cursor: pointer; margin: 24px auto; display: block; }
        #micBtn.active { background: #FFDA1A; color: #0051BA; }
    </style>
</head>
<body>
<div class="container">
    <h1>Voice Chat Live API Test</h1>
    <div id="status">Status: <span id="statusText">Idle</span></div>
    <button id="micBtn">üé§</button>
    <div id="log"></div>
</div>

<script>
class AudioClient {
    constructor(serverUrl) {
        this.serverUrl = serverUrl;
        this.ws = null;
        this.isRecording = false;
        this.audioContext = null;
        this.recorder = null;
        this.audioQueue = [];
        this.sessionActive = false;
    }
    connect() {
        this.ws = new WebSocket(this.serverUrl, 'voice-chat');
        this.ws.onopen = () => {
            this.log('WebSocket connected');
            // G·ª≠i start_session ngay khi k·∫øt n·ªëi
            this.ws.send(JSON.stringify({ type: 'start_session', user_id: 'test_user' }));
        };
        this.ws.onmessage = (event) => this.handleMessage(event);
        this.ws.onerror = (e) => this.log('WebSocket error: ' + e.message);
        this.ws.onclose = () => this.log('WebSocket closed');
    }
    handleMessage(event) {
        try {
            if (typeof event.data === 'string') {
                this.log('Received: ' + event.data);
                const msg = JSON.parse(event.data);
                if (msg.type === 'adk_event' && msg.event_type === 'error') {
                    this.log('‚ùå ADK Error: ' + (msg.data && msg.data.error));
                }
                if (msg.type === 'session_started') {
                    this.sessionActive = true;
                    this.log('‚úÖ Session started, ready for audio');
                }
                if (msg.type === 'session_stopped') {
                    this.sessionActive = false;
                    this.log('üõë Session stopped');
                }
            } else {
                this.log('Received binary data (' + event.data.byteLength + ' bytes)');
            }
        } catch (e) { this.log('Error parsing message: ' + e); }
    }
    async startRecording() {
        if (!navigator.mediaDevices) { this.log('No mediaDevices support'); return; }
        if (!this.sessionActive) { this.log('Session not active!'); return; }
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const source = this.audioContext.createMediaStreamSource(stream);
        const processor = this.audioContext.createScriptProcessor(4096, 1, 1);
        source.connect(processor);
        processor.connect(this.audioContext.destination);
        processor.onaudioprocess = (e) => {
            if (!this.isRecording) return;
            const input = e.inputBuffer.getChannelData(0);
            const pcm = new Int16Array(input.length);
            for (let i = 0; i < input.length; i++) {
                let s = Math.max(-1, Math.min(1, input[i]));
                pcm[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            this.sendAudioChunk(pcm);
        };
        this.recorder = { stream, processor };
        this.isRecording = true;
        this.log('üé§ Recording started');
    }
    stopRecording() {
        if (this.recorder) {
            this.recorder.processor.disconnect();
            this.recorder.stream.getTracks().forEach(track => track.stop());
            this.isRecording = false;
            this.log('üõë Recording stopped');
        }
    }
    sendAudioChunk(pcm) {
        if (this.ws && this.ws.readyState === WebSocket.OPEN && this.sessionActive) {
            const b64 = btoa(String.fromCharCode(...new Uint8Array(pcm.buffer)));
            this.ws.send(JSON.stringify({ type: 'audio', data: b64 }));
        }
    }
    log(msg) {
        const logDiv = document.getElementById('log');
        logDiv.innerHTML += msg + '<br>';
        logDiv.scrollTop = logDiv.scrollHeight;
    }
}

const SERVER_URL = 'ws://192.168.1.8:8003'; // ƒê·ªïi th√†nh IP/host c·ªßa b·∫°n n·∫øu c·∫ßn

const client = new AudioClient(SERVER_URL);
client.connect();

document.getElementById('micBtn').onclick = async function() {
    if (!client.isRecording) {
        if (!client.sessionActive) {
            client.log('‚ùóÔ∏èSession ch∆∞a s·∫µn s√†ng, h√£y ƒë·ª£i "Session started"');
            return;
        }
        document.getElementById('statusText').textContent = 'Recording...';
        this.classList.add('active');
        await client.startRecording();
    } else {
        document.getElementById('statusText').textContent = 'Idle';
        this.classList.remove('active');
        client.stopRecording();
    }
};
</script>
</body>
</html>